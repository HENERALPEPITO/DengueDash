%   Filename    : chapter_4.tex 
\chapter{Preliminary Results/System Prototype}
\section{Data Gathering}
The data for dengue case prediction was gathered from a variety of reliable sources, enabling a comprehensive dataset spanning from January 2011 to October 2024. This dataset includes 720 rows of data, each containing weekly records of dengue cases along with corresponding meteorological variables, such as rainfall, temperature, and humidity.
\begin{enumerate}
	\item Dengue Case Data: The primary source of historical dengue cases came from the Humanitarian Data Exchange and the Western Visayas Center for Health Development (WVCHD). The dataset, accessed through Freedom of Information (FOI) requests, provided robust case numbers for the Western Visayas region. The systematic collection of these data points was essential for establishing a reliable baseline for model training and evaluation.
	\item Weather Data: Weekly weather data was obtained by web scraping from Weather Underground, allowing access to rainfall, temperature, wind, and humidity levels that correlate with dengue prevalence.
\end{enumerate}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.75\textwidth]{data_snippet}
	\caption{Snippet of the Combined Dataset}
	\label{fig:data_snippet}
\end{figure}

\section{Exploratory Data Analysis}

Figure \ref{fig:data_snippet} illustrates the trend of weekly dengue cases over time. The data reveals periodic spikes in the number of cases, suggesting a seasonal pattern in dengue cases. Notably, peak cases are observed during certain periods, potentially aligning with specific climatic conditions such as increased rainfall or temperature changes. This underscores the importance of incorporating climate variables into the forecasting model.

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.75\textwidth]{dengue_trend}
	\caption{Trend of Dengue Cases}
	\label{fig:data_trend}
\end{figure}

Figure 4.3 presents a detailed heatmap showing the correlations among all variables. The heatmap highlights the interdependencies between climatic variables and their respective relationships with dengue cases. Such relationships provide a deeper understanding of how these variables interact and affect dengue case trends, which can guide feature selection for the predictive model.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.75\textwidth]{correlation_heatmap}
	\caption{Correlation Heatmap}
	\label{fig:correlation_heatmap}
\end{figure}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.75\textwidth]{correlation_bar}
	\caption{Ranking of Correlations}
	\label{fig:correlation_bar}
\end{figure}

Figure 4.4 shows the ranking of correlation coefficients between dengue cases and selected features, including rainfall, humidity, maximum temperature, average temperature, minimum temperature, and wind speed. Among these, rainfall exhibits the highest positive correlation with dengue cases (correlation coefficient ~0.13), followed by humidity (~0.10) and maximum temperature (0.09). 

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.75\textwidth]{lagged_correlation_bar}
	\caption{Ranking of Correlations (with lagged effects)}
	\label{fig:lagged_correlation_bar}
\end{figure}

Figure 4.5 shows the ranking of correlation coefficients between dengue cases and selected features, with the addition of lagged effects. The analysis reveals no improvement in correlation when lagged variables are compared to direct observations. This suggests that the observed values of rainfall, humidity, and maximum temperature remain the most significant predictors for dengue case forecasting. Overall, the exploratory data analysis highlights the significance of rainfall, humidity, and max temperature variables in dengue case forecasting.



\section{Model Training}
The proposed Dengue Watch system utilized four distinct models to forecast weekly dengue cases: Long Short-Term Memory (LSTM) networks, Autoregressive Integrated Moving Average (ARIMA), Seasonal ARIMA (SARIMA), and Kalman Filter. Each model was trained on a dataset containing 720 weeks of historical dengue cases from 2010 to 2024, with meteorological variables such as max temperature, humidity, and rainfall.

To optimize predictive performance, hyperparameter tuning was conducted individually for each model, refining parameters to achieve the most accurate and reliable forecasts. Following training, the models were rigorously evaluated against the dataset using a set of key performance metrics, including Mean Squared Error (MSE) and Root Mean Squared Error (RMSE).

The table below provides a summary and comparative analysis of each model’s results across these metrics, offering insights into the strengths and limitations of each forecasting technique for dengue case prediction in Iloilo City. 

\begin{table}[h!]
	\centering
	\begin{tabular}{|l|c|c|}
		\hline
		\textbf{Model} & \textbf{MSE} & \textbf{RMSE} \\ \hline
		\textbf{LSTM} & \textbf{277.71} & \textbf{16.66} \\ \hline
		\begin{tabular}[c]{@{}l@{}}\textbf{Seasonal ARIMA} \\ \textbf{(2, 0, 2) (0, 1,1)}\end{tabular} & \textbf{1109.69} & \textbf{33.31} \\ \hline
		\textbf{ARIMA (1, 2, 2)} & \textbf{1521.48} & \textbf{39.01} \\ \hline
		\textbf{Kalman Filter} & \textbf{1474.82} & \textbf{38.40} \\ \hline
	\end{tabular}
	\caption{Comparison of Models}
	\label{tab:comparison_of_models}
\end{table}

\subsection{LSTM Model}
The LSTM model architecture consisted of an input layer, a single LSTM layer with 64 units and ReLU activation, followed by a dense layer with a single output neuron to predict the dengue case count. Key hyperparameters included:
\begin{itemize}
	\item Window Size: 5, 10, and 20 weeks, representing the time steps used in the sequence data for each prediction.
	\item Epochs: 100 epochs were used for training, balancing sufficient training time with computational efficiency also implementing early stopping to avoid overfitting.
	\item Batch Size: 1, allowing the model to process one sequence at a time, which is beneficial for small datasets but increases training time.
	\item Optimizer: The Adam optimizer was chosen for its adaptive learning capabilities and stability in training. A custom learning rate of 0.0001 was set to ensure gradual convergence and minimize risk of overfitting.
\end{itemize}

The dataset was split into training and test sets to evaluate the model’s performance and generalizability:
\begin{itemize}
	\item \textbf{Training Set:} 80\% of the data (572 sequences) was used for model training, enabling the LSTM to learn underlying patterns in historical dengue case trends and their relationship with weather variables.
	\item \textbf{Test Set:} The remaining 20\% of the data (148 sequences) was reserved for testing
\end{itemize}

The training process was conducted using three distinct window sizes—5 weeks, 10 weeks, and 20 weeks—to identify the optimal sequence length of weeks for input into the LSTM model, thereby enhancing forecasting performance. The following plots illustrate the performance of the model in predicting dengue cases for each of the specified window sizes.

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{lstm_comparison}
	\caption{Comparison of Window Sizes}
	\label{fig:lstm_comparison}
\end{figure}

The evaluation metrics included Mean Squared Error (MSE) and Root Mean Squared Error (RMSE), which assess the accuracy of the model's predictions.
\begin{table}[h!]
	\centering
	\begin{tabular}{|l|c|c|}
		\hline
		\textbf{Window Size} & \textbf{MSE} & \textbf{RMSE} \\ \hline
		\textbf{5} & \textbf{282.69} & \textbf{16.81} \\ \hline
		\textbf{10} & \textbf{277.71} & \textbf{16.66} \\ \hline
		\textbf{15} & \textbf{289.63} & \textbf{17.02} \\ \hline
	\end{tabular}
	\caption{Comparison of Window Sizes}
	\label{tab:comparison_of_lstm}
\end{table}

The results indicate that a window size of 10 weeks provides the most accurate predictions, as evidenced by the lowest MSE and RMSE values. This suggests that using a 10-week sequence length effectively balances the temporal dependencies captured by the model and the computational complexity of training.



\section*{Training and Testing Data Division for ARIMA and Seasonal Arima}
Both models utilized an \textbf{80\%-20\% split} to evaluate generalizability:
\begin{itemize}
	\item \textbf{Training Set}: 80\% of the data was used for training, allowing the models to learn underlying patterns in the dataset.
	\item \textbf{Test Set}: 20\% of the data was reserved for testing, providing an unbiased assessment of the models' performance on unseen data.
\end{itemize}
\subsection{ARIMA Model}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{line_graph_Arima}
	\caption{ARIMA Prediction Results for Test Set}
	\label{fig:Arima_result}
\end{figure}

The ARIMA model was developed to capture non-seasonal trends in the data. To determine the best model configuration, grid search was used to explore various combinations of ARIMA parameters, ultimately selecting \textbf{ARIMA(1, 2, 2)}. The model was iteratively refined over \textbf{400 iterations} to ensure convergence to an optimal solution. Key details are as follows:

\begin{enumerate}
	\item \textbf{Data Preprocessing:}  
	Prepare the dataset by handling any missing values and scaling the data if necessary to improve model convergence and stability.
	
	\item \textbf{Hyperparameter Tuning:}  
	Use a grid search on potential ARIMA parameters $(p, d, q)$ to identify the configuration that minimizes error. The optimal parameters were found to be \textbf{(1, 2, 2)}.
	
	\item \textbf{Model Training:}
	\begin{itemize}
		\item Set the number of iterations to 400 to ensure thorough training and convergence.
		\item Train the ARIMA model on 80\% of the data and reserve 20\% for testing.
	\end{itemize}
	
	\item \textbf{Evaluation:}  
	After training, the ARIMA model was evaluated on the test data, yielding the following performance metrics:
	\begin{itemize}
		\item \textbf{MSE (Mean Squared Error)}: 1521.48
		\item \textbf{RMSE (Root Mean Squared Error)}: 39.01
	\end{itemize}
\end{enumerate}


\section*{Seasonal ARIMA (SARIMA) Model}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{line_graph_Sarima}
	\caption{Seasonal ARIMA Prediction Results for Test Set}
	\label{fig:Sarima_result}
\end{figure}

This model incorporates seasonal parameters, which were tuned using grid search to find the best configuration: \textbf{SARIMA(2, 0, 2)(0, 1, 1)[52]}. As with ARIMA, \textbf{400 iterations} were applied to ensure a robust fit.

\subsection*{Steps to Create the SARIMA Model:}
\begin{enumerate}
	\item \textbf{Data Preprocessing:}  
	Ensure data readiness by filling any missing values and scaling as needed.
	
	\item \textbf{Seasonality Analysis:}  
	Examine the dataset for seasonal patterns. A periodicity of \textbf{52 weeks} was identified, making SARIMA a suitable choice for capturing yearly seasonality.
	
	\item \textbf{Hyperparameter Tuning:}  
	Conduct grid search to identify the best set of parameters $(p, d, q)(P, D, Q)[S]$, where:
	\begin{itemize}
		\item \textbf{(p, d, q)} are the non-seasonal parameters,
		\item \textbf{(P, D, Q)} are the seasonal parameters, and
		\item \textbf{S} is the season length.
	\end{itemize}
	The optimal configuration found was \textbf{(2, 0, 2)(0, 1, 1)[52]}.
	
	\item \textbf{Model Training:}
	\begin{itemize}
		\item Set the iteration count to 400 for enhanced model robustness.
		\item Train the model on the 80\% training dataset and reserve the remaining 20\% for testing.
	\end{itemize}
	
	\item \textbf{Evaluation:}  
	The SARIMA model yielded the following error metrics:
	\begin{itemize}
		\item \textbf{MSE}: 1109.69
		\item \textbf{RMSE}: 33.31
	\end{itemize}
	The SARIMA model outperformed the ARIMA model in terms of lower MSE and RMSE values, indicating its effectiveness in capturing the seasonal patterns in the data.
\end{enumerate}

\subsection{Kalman Filter Model}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{line_graph_Kalman}
	\caption{Kalman Filter Prediction Results for Test Set}
	\label{fig:Kalman_result}
\end{figure}

\section*{Kalman Filter Methodology with Matrix Calculations}

\textbf{Measurement Acquisition}: Obtain the measurement \( z_k \) of the system's state with associated confidence. This measurement matrix provides a noisy observation of the true state.

The dataset was split into training and test sets to evaluate the Kalman Filter's performance and generalizability:
\begin{itemize}
	\item \textbf{Training Set}: 80\% of the data was used for training, enabling the Kalman Filter model to capture key patterns.
	\item \textbf{Test Set}: The remaining 20\% of the data was reserved for testing.
\end{itemize}

\textbf{Prediction Step}:
\begin{itemize}
	\item Predict the next state:
	\[
	\hat{x}_{k|k-1} = A \hat{x}_{k-1|k-1} + B u_k
	\]
	where \( A \) is the state transition matrix and \( B \) is the control matrix.
	
	\item Update the state covariance:
	\[
	P_{k|k-1} = A P_{k-1|k-1} A^T + Q
	\]
	where \( Q \) is the process noise covariance matrix.
\end{itemize}

\textbf{Compute Residual}: Calculate the residual
\[
y_k = z_k - H \hat{x}_{k|k-1}
\]
where \( H \) is the observation matrix. This residual represents the new information from the measurement.

\textbf{Scaling Factor (Kalman Gain)}:
\begin{itemize}
	\item Compute the Kalman Gain:
	\[
	K_k = P_{k|k-1} H^T (H P_{k|k-1} H^T + R)^{-1}
	\]
	where \( R \) is the measurement noise covariance matrix.
	
	\item The Kalman Gain determines the weight of the measurement relative to the prediction.
\end{itemize}

\textbf{State Update}:
\begin{itemize}
	\item Update the state estimate:
	\[
	\hat{x}_{k|k} = \hat{x}_{k|k-1} + K_k y_k
	\]
	blending the prediction and measurement.
\end{itemize}

\textbf{Uncertainty Update}:
\begin{itemize}
	\item Update the state covariance:
	\[
	P_{k|k} = (I - K_k H) P_{k|k-1}
	\]
	where \( I \) is the identity matrix.
\end{itemize}

\textbf{Model Evaluation}:
Upon testing, the Kalman Filter produced a Mean Squared Error (MSE) of 1474.82 and a Root Mean Squared Error (RMSE) of 38.40.

\clearpage
\section{Preliminary System Requirements}
\subsection{Backend Requirements}
\subsubsection{Database Structure Design}
Determining how data flows and how it would be structured is crucial in creating the system as it defines how extendible and flexible it would be for future features and updates. Thus, creating a comprehensive map of data ensures proper normalization that eliminates data redundancy and improves data integrity. Figure \ref{fig:er_diagram} depicts the designed database schema that showcases the relationship between the application's entities. 
\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{er_diagram}
	\caption{Entity-Relationship Database Schema Hybrid Diagram for DengueDash Database Structure}
	\label{fig:er_diagram}
\end{figure}

\subsection{User Interface Requirements}
\subsubsection{Admin Interface}
\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{admin}
	\caption{Use Case Diagram for Admin}
	\label{fig:admin-use-case}
\end{figure}
Figure \ref{fig:admin-use-case} shows the possible tasks that the admin can do in the application. To protect the integrity of data, only the admins can register and delete accounts. Both account creation and deletion will be done within the application.

\subsubsection{Encoder Interface}
\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{encoder}
	\caption{Use Case Diagram for Encoder}
	\label{fig:encoder-use-case}
\end{figure}

Figure \ref{fig:encoder-use-case}, on the other hand, illustrates the use cases for the system's primary users. Since only the admin accounts can register a user, the registration process is not part of it. Instead, the main features, which include reporting and viewing records, are the only permitted actions for this type of user. The said processes can be done in the application by filling out a form with details required for each dengue case. 
As data is entered, it will be consolidated for model training and used for further forecasting of dengue cases.


\subsection{Security and Validation Requirements}
\subsubsection{Password Encryption}
Storing passwords as plain text in the database is a disgrace and a mortal sin in production. It is important to implement precautionary methods such as hashing and salting, followed by encryption with a strong algorithm, to prevent bad actors from using the accounts for malicious transactions. By default, Django generates a unique random salt for each password and encrypts it with Password-Based Key Derivation Function 2 (PBKDF2) with a SHA256 hash function. Utilizing these techniques ensures that in the event of a data breach, cracking these passwords would be time-consuming and useless for the attackers. 

\subsubsection{Authentication}
DengueWatch utilizes JSON Web Tokens (JWT) to authenticate the user. Since the mechanism operates in a stateless manner, tokens are served only after a successful login, eliminating the need for the server to keep a record of the token, which is vulnerable to session hijacking. In addition, these tokens are signed with a secret key, ensuring they have not been tampered with. 

\subsubsection{Data Validation}
Both the backend and frontend should validate the input from the user to preserve data integrity. Thus, Zod is implemented in the latter to help catch invalid inputs from the user. By doing this, the user can only send proper requests to the server which streamlines the total workflow. On the other hand, Django has also a built-in validator that checks the data type and ensures that the input matches the expected format on the server side. These validation processes ensure that only valid and properly formatted data is accepted, which reduces the risk of errors and ensures consistency across the web application. 

\subsection{Testing Process}
\begin{figure}[H]
	\centering
	\includegraphics[height=10cm]{testing_process}
	\caption{Testing Process for DengueWatch}
	\label{fig:testing-process}
\end{figure}

As the system requirements and functionalities have been mentioned above, it is important to implement testing to validate the system's performance and efficacy. Since dengue reports include confidential information, anonymized historical dengue reports were used to train the model and create the foundational architecture of the system. By using functional tests, data validation and visualization can be ensured for further continual improvements. Security testing is also important as it is needed to safeguard confidential information when the system is deployed. It includes proper authentication, permission views, and mitigating common injection attacks. Finally, a user acceptance test from the prospected users, in this case, the Iloilo City Epidemiology and Surveillance Unit, is crucial to assess its performance and user experience. It enables the developers to confirm if the system meets the needs of the problem, and once confirmed, it will be deployed and further evaluated to ensure stability and reliability in live operation. 

\section{System Prototype}
\subsection{Guest Interface}
The Guest Interface is intended for all visitors of the web application. It shows the related statistics for dengue cases in a particular area and time. As the system is still in its testing phase, the data converted into charts shown in Figure \ref{fig:guest_dashboard} are generated from Python's Faker library. 
\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{guest_dashboard}
	\caption{Dashboard for Guests}
	\label{fig:guest_dashboard}
\end{figure}
\subsection{Personnel Interface}
\subsubsection{User Authentication, and Login}
To protect the data's integrity in production, it has been decided that the registration process will not be visible. Instead, an admin must register a user using a different interface. As of the moment, registering a user is done using API via Postman. In the login process, the system implements HTTP-only cookies that contains the JSON Web Tokens (JWT) to protect against XSS attacks. After proper credentials have been provided, it will redirect to the user's home page.
\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{login}
	\caption{Login Page for Users}
	\label{fig:login_page}
\end{figure}
\subsubsection{Encoder's View}
Figures \ref{fig:case_report_form_1} and \ref{fig:case_report_form_2} show the digitized counterpart of the form obtained from the Iloilo Provincial Epidemiology and Surveillance Unit. As the system aims to support expandability for future features, some fields were modified to accommodate more detailed input. It is worth noting that all of the included fields adhere to the latest Philippine Integrated Disease and Surveillance Response (PIDSR) Dengue Forms, which the referenced form was based on. By doing this, it is assumed that the targeted users will have a familiarity when deployed on a national scale. On a further note, the case form includes the patient's basic information, dengue vaccination status, consultation details, laboratory results, and the outcome. 
\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{case_report_form_1}
	\caption{First Part of Case Report Form}
	\label{fig:case_report_form_1}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{case_report_form_2}
	\caption{Second Part of Case Report Form}
	\label{fig:case_report_form_2}
\end{figure}
\clearpage
Once the data generated from the case report form is validated, it will be assigned as a new case and can be accessed through the Dengue Reports page, as shown in Figure \ref{fig:dengue_reports}. The said page displays basic information about the patient related to a specific case, including their name, address, date of consultation, and clinical and case classifications. 
It is also worth noting that it only shows cases the user is permitted to view. For example, in a local Disease Reporting Unit (DRU) setting, the user can only access records that came from the same DRU. On the other hand, in a consolidated surveillance unit such as a regional and provincial quarter, its users can view all the records that came from all the DRUs that report to them. Moving forward, Figure \ref{fig:case_report} shows the detailed case report of the patient on a particular consultation date. 
\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{dengue_reports}
	\caption{Dengue Reports}
	\label{fig:dengue_reports}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{case_report}
	\caption{Detailed Case Report}
	\label{fig:case_report}
\end{figure}
